{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42226"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14226"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def get_unique_dict(dictionary_1, dictionary_2):\n",
    "    dictionary = {}\n",
    "\n",
    "    for key in range(42226):\n",
    "        if key < 28000:\n",
    "            dictionary[key] = dictionary_1[key]\n",
    "        else:\n",
    "            dictionary[key] = dictionary_2[key]\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "with open('./data/yolo_v8x/yolo_v8x_1_dictionary_full_train_0-28000.p', 'rb') as f:\n",
    "    dictionary_1 = pickle.load(f)\n",
    "\n",
    "with open('./data/yolo_v8x/yolo_v8x_1_dictionary_full_train_28000-42000.p', 'rb') as f:\n",
    "    dictionary_2 = pickle.load(f)\n",
    "\n",
    "# merge the two dictionaries\n",
    "dictionary = get_unique_dict(dictionary_1, dictionary_2)\n",
    "\n",
    "\n",
    "# save the dictionary\n",
    "# with open('./data/yolo_v8x/yolo_v8x_1_dictionary_full_train.p', 'wb') as f:\n",
    "#     pickle.dump(dictionary, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE with yolov5l6\n",
    "\n",
    "In this assessment, we are analyzing the baseline performance. The YOLOv5l6 model was utilized to locate the boxes, while the corresponding text for these boxes was computed in advance using CLIP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42226/42226 [00:11<00:00, 3813.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[135.,  36., 304., 224.],\n",
      "        [  0.,  42., 235., 465.],\n",
      "        [281., 486., 399., 576.],\n",
      "        ...,\n",
      "        [376.,  89., 487., 379.],\n",
      "        [  0., 245.,  48., 399.],\n",
      "        [ 30.,  65., 382., 638.]]) tensor([[  0.0000,  45.9500, 238.9200, 454.5900],\n",
      "        [  0.0000,  45.9500, 238.9200, 454.5900],\n",
      "        [213.7200, 456.5100, 405.7300, 590.2600],\n",
      "        ...,\n",
      "        [141.3400,  86.7100, 256.6700, 375.4600],\n",
      "        [ 31.7100,  67.0300, 384.0000, 640.0000],\n",
      "        [ 31.7100,  67.0300, 384.0000, 640.0000]])\n",
      "assert same dimensionality True\n",
      "torch.Size([72601, 4]) torch.Size([72601, 4])\n",
      "mean iou on the train set: 0.52733845\n",
      "accuracy on the train set: T=0.3 0.567967383369375 T=0.5 0.5243178468616134 T=0.75 0.49508959931681384\n",
      "precision on the train set: T=0.3 0.567967383369375 T=0.5 0.5243178468616134 T=0.75 0.49508959931681384\n",
      "recall on the train set: T=0.3 0.567967383369375 T=0.5 0.5243178468616134 T=0.75 0.49508959931681384\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "def get_unique_dict(dictionary_1, dictionary_2):\n",
    "    dictionary = {}\n",
    "\n",
    "    for key in range(42226):\n",
    "        if key < 28000:\n",
    "            dictionary[key] = dictionary_1[key]\n",
    "        else:\n",
    "            dictionary[key] = dictionary_2[key]\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "with open('./data/yolo_v8x/yolo_v8x_1_dictionary_full_train_0-28000.p', 'rb') as f:\n",
    "    dictionary_1 = pickle.load(f)\n",
    "\n",
    "with open('./data/yolo_v8x/yolo_v8x_1_dictionary_full_train_28000-42000.p', 'rb') as f:\n",
    "    dictionary_2 = pickle.load(f)\n",
    "\n",
    "# merge the two dictionaries\n",
    "dictionary = get_unique_dict(dictionary_1, dictionary_2)\n",
    "\n",
    "\n",
    "def load_the_best_matching_box(dictionary):\n",
    "    box_target = []\n",
    "    box_pred = []\n",
    "    \n",
    "    # with open(file_name, 'rb') as f:\n",
    "    #     dictionary = pickle.load(f)\n",
    "        \n",
    "    for sample in tqdm(dictionary.keys()):\n",
    "        \n",
    "        try:\n",
    "            # get the sample\n",
    "            element = dictionary[sample]\n",
    "            \n",
    "            for sim, cap in zip(element['text_similarity'],element['caption']):\n",
    "                \n",
    "                # get the max similarity index\n",
    "                max_sim_index = torch.argmax(sim).numpy()\n",
    "                \n",
    "                # gete the  bbox_target\n",
    "                box_pred.append(element['df_boxes'].loc[max_sim_index][:4].values.astype('int'))\n",
    "                box_target.append(element['bbox_target'])\n",
    "        except:\n",
    "            KeyError: print('error in sample:', sample)\n",
    "            \n",
    "    box_pred = torch.stack([torch.Tensor(p) for p in box_pred])\n",
    "    box_target = torch.tensor(box_target)\n",
    "    \n",
    "    # convert the box_pred to x1, y1, x2, y2\n",
    "    box_target[:, 2] = box_target[:, 0] + box_target[:, 2]\n",
    "    box_target[:, 3] = box_target[:, 1] + box_target[:, 3]\n",
    "        \n",
    "    return box_pred, box_target\n",
    "\n",
    "\n",
    "\n",
    "box_pred, box_target = load_the_best_matching_box(dictionary)\n",
    "\n",
    "\n",
    "\n",
    "print(box_pred,box_target)\n",
    "\n",
    "\n",
    "print('assert same dimensionality',len(box_pred) == len(box_target))\n",
    "\n",
    "\n",
    "\n",
    "print(box_target.shape,  box_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "mean_iou = []\n",
    "accuracy_0_3 = []\n",
    "accuracy_0_5 = []\n",
    "accuracy_0_75 = []\n",
    "\n",
    "def iou(box1, box2):\n",
    "    # get the coordinates of bounding boxes\n",
    "    b1_x1, b1_y1, b1_x2, b1_y2 = box1\n",
    "    b2_x1, b2_y1, b2_x2, b2_y2 = box2\n",
    "    \n",
    "    # get the corrdinates of the intersection rectangle\n",
    "    inter_rect_x1 =  max(b1_x1, b2_x1)\n",
    "    inter_rect_y1 =  max(b1_y1, b2_y1)\n",
    "    inter_rect_x2 =  min(b1_x2, b2_x2)\n",
    "    inter_rect_y2 =  min(b1_y2, b2_y2)\n",
    "    \n",
    "    # Intersection area\n",
    "    inter_area = max(inter_rect_x2 - inter_rect_x1 + 1, 0) * max(inter_rect_y2 - inter_rect_y1 + 1, 0)\n",
    "    \n",
    "    # Union Area\n",
    "    b1_area = (b1_x2 - b1_x1 + 1)*(b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1)*(b2_y2 - b2_y1 + 1)\n",
    "    \n",
    "    iou = inter_area / (b1_area + b2_area - inter_area)\n",
    "    \n",
    "    return iou\n",
    "    \n",
    "for b_t, b_p in zip(box_target, box_pred):\n",
    "    \n",
    "    IoU = iou(b_t, b_p)\n",
    "\n",
    "    # get the iou\n",
    "    mean_iou.append(IoU)\n",
    "\n",
    "    # get the accuracy\n",
    "    if IoU > 0.3:\n",
    "        accuracy_0_3.append(1)\n",
    "    else:\n",
    "        accuracy_0_3.append(0)\n",
    "\n",
    "    if IoU > 0.5:\n",
    "        accuracy_0_5.append(1)\n",
    "    else:\n",
    "        accuracy_0_5.append(0)\n",
    "\n",
    "    if IoU > 0.75:\n",
    "        accuracy_0_75.append(1)\n",
    "    else:   \n",
    "        accuracy_0_75.append(0)\n",
    "\n",
    "# get the mean iou\n",
    "mean_iou_m = torch.stack(mean_iou).mean().numpy()\n",
    "\n",
    "\n",
    "# get the accuracy\n",
    "accuracy_0_3_m = np.array(accuracy_0_3).mean()\n",
    "accuracy_0_5_m = np.array(accuracy_0_5).mean()\n",
    "accuracy_0_75_m = np.array(accuracy_0_75).mean()\n",
    "\n",
    "# get precision\n",
    "precision_0_3 = np.array(accuracy_0_3).sum() / len(accuracy_0_3)\n",
    "precision_0_5 = np.array(accuracy_0_5).sum() / len(accuracy_0_5)\n",
    "precision_0_75 = np.array(accuracy_0_75).sum() / len(accuracy_0_75)\n",
    "\n",
    "# get recall\n",
    "recall_0_3 = np.array(accuracy_0_3).sum() / len(box_target)\n",
    "recall_0_5 = np.array(accuracy_0_5).sum() / len(box_target)\n",
    "recall_0_75 = np.array(accuracy_0_75).sum() / len(box_target)\n",
    "\n",
    "\n",
    "# mean iou on the train set\n",
    "print('mean iou on the train set:',mean_iou_m)\n",
    "\n",
    "# accuracy on the train set\n",
    "print('accuracy on the train set:', 'T=0.3',accuracy_0_3_m, 'T=0.5',accuracy_0_5_m, 'T=0.75',accuracy_0_75_m)\n",
    "\n",
    "# precision on the train set\n",
    "print('precision on the train set:', 'T=0.3',precision_0_3, 'T=0.5',precision_0_5, 'T=0.75',precision_0_75)\n",
    "\n",
    "# recall on the train set\n",
    "print('recall on the train set:', 'T=0.3',recall_0_3, 'T=0.5',recall_0_5, 'T=0.75',recall_0_75)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5023/5023 [00:01<00:00, 3565.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[374.,  69., 510., 262.],\n",
      "        [374.,  69., 510., 262.],\n",
      "        [  0., 171.,  22., 331.],\n",
      "        ...,\n",
      "        [202., 277., 334., 445.],\n",
      "        [224.,   0., 346., 137.],\n",
      "        [224.,   0., 346., 137.]]) tensor([[374.3100,  65.0600, 510.3500, 267.0000],\n",
      "        [374.3100,  65.0600, 510.3500, 267.0000],\n",
      "        [ 93.9500,  83.2900, 598.5600, 373.8600],\n",
      "        ...,\n",
      "        [348.5800, 230.9100, 480.0000, 471.1400],\n",
      "        [212.8200,   0.0000, 355.9000, 132.4100],\n",
      "        [212.8200,   0.0000, 355.9000, 132.4100]])\n",
      "assert same dimensionality True\n",
      "torch.Size([8595, 4]) torch.Size([8595, 4])\n",
      "mean iou on the train set: 0.52096236\n",
      "accuracy on the train set: T=0.3 0.5647469458987784 T=0.5 0.5161140197789412 T=0.75 0.48632926119837117\n",
      "precision on the train set: T=0.3 0.5647469458987784 T=0.5 0.5161140197789412 T=0.75 0.48632926119837117\n",
      "recall on the train set: T=0.3 0.5647469458987784 T=0.5 0.5161140197789412 T=0.75 0.48632926119837117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "with open('./data/yolo_v8x/yolo_v8x_1_dictionary_full_test.p', 'rb') as f:\n",
    "    dictionary = pickle.load(f)\n",
    "\n",
    "\n",
    "def load_the_best_matching_box(dictionary):\n",
    "    box_target = []\n",
    "    box_pred = []\n",
    "    \n",
    "    # with open(file_name, 'rb') as f:\n",
    "    #     dictionary = pickle.load(f)\n",
    "        \n",
    "    for sample in tqdm(dictionary.keys()):\n",
    "        \n",
    "        try:\n",
    "            # get the sample\n",
    "            element = dictionary[sample]\n",
    "            \n",
    "            for sim, cap in zip(element['text_similarity'],element['caption']):\n",
    "                \n",
    "                # get the max similarity index\n",
    "                max_sim_index = torch.argmax(sim).numpy()\n",
    "                \n",
    "                # gete the  bbox_target\n",
    "                box_pred.append(element['df_boxes'].loc[max_sim_index][:4].values.astype('int'))\n",
    "                box_target.append(element['bbox_target'])\n",
    "        except:\n",
    "            KeyError: print('error in sample:', sample)\n",
    "            \n",
    "    box_pred = torch.stack([torch.Tensor(p) for p in box_pred])\n",
    "    box_target = torch.tensor(box_target)\n",
    "    \n",
    "    # convert the box_pred to x1, y1, x2, y2\n",
    "    box_target[:, 2] = box_target[:, 0] + box_target[:, 2]\n",
    "    box_target[:, 3] = box_target[:, 1] + box_target[:, 3]\n",
    "        \n",
    "    return box_pred, box_target\n",
    "\n",
    "\n",
    "\n",
    "box_pred, box_target = load_the_best_matching_box(dictionary)\n",
    "\n",
    "\n",
    "\n",
    "print(box_pred,box_target)\n",
    "\n",
    "\n",
    "print('assert same dimensionality',len(box_pred) == len(box_target))\n",
    "\n",
    "\n",
    "\n",
    "print(box_target.shape,  box_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "mean_iou = []\n",
    "accuracy_0_3 = []\n",
    "accuracy_0_5 = []\n",
    "accuracy_0_75 = []\n",
    "\n",
    "def iou(box1, box2):\n",
    "    # get the coordinates of bounding boxes\n",
    "    b1_x1, b1_y1, b1_x2, b1_y2 = box1\n",
    "    b2_x1, b2_y1, b2_x2, b2_y2 = box2\n",
    "    \n",
    "    # get the corrdinates of the intersection rectangle\n",
    "    inter_rect_x1 =  max(b1_x1, b2_x1)\n",
    "    inter_rect_y1 =  max(b1_y1, b2_y1)\n",
    "    inter_rect_x2 =  min(b1_x2, b2_x2)\n",
    "    inter_rect_y2 =  min(b1_y2, b2_y2)\n",
    "    \n",
    "    # Intersection area\n",
    "    inter_area = max(inter_rect_x2 - inter_rect_x1 + 1, 0) * max(inter_rect_y2 - inter_rect_y1 + 1, 0)\n",
    "    \n",
    "    # Union Area\n",
    "    b1_area = (b1_x2 - b1_x1 + 1)*(b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1)*(b2_y2 - b2_y1 + 1)\n",
    "    \n",
    "    iou = inter_area / (b1_area + b2_area - inter_area)\n",
    "    \n",
    "    return iou\n",
    "    \n",
    "for b_t, b_p in zip(box_target, box_pred):\n",
    "    \n",
    "    IoU = iou(b_t, b_p)\n",
    "\n",
    "    # get the iou\n",
    "    mean_iou.append(IoU)\n",
    "\n",
    "    # get the accuracy\n",
    "    if IoU > 0.3:\n",
    "        accuracy_0_3.append(1)\n",
    "    else:\n",
    "        accuracy_0_3.append(0)\n",
    "\n",
    "    if IoU > 0.5:\n",
    "        accuracy_0_5.append(1)\n",
    "    else:\n",
    "        accuracy_0_5.append(0)\n",
    "\n",
    "    if IoU > 0.75:\n",
    "        accuracy_0_75.append(1)\n",
    "    else:   \n",
    "        accuracy_0_75.append(0)\n",
    "\n",
    "# get the mean iou\n",
    "mean_iou_m = torch.stack(mean_iou).mean().numpy()\n",
    "\n",
    "\n",
    "# get the accuracy\n",
    "accuracy_0_3_m = np.array(accuracy_0_3).mean()\n",
    "accuracy_0_5_m = np.array(accuracy_0_5).mean()\n",
    "accuracy_0_75_m = np.array(accuracy_0_75).mean()\n",
    "\n",
    "# get precision\n",
    "precision_0_3 = np.array(accuracy_0_3).sum() / len(accuracy_0_3)\n",
    "precision_0_5 = np.array(accuracy_0_5).sum() / len(accuracy_0_5)\n",
    "precision_0_75 = np.array(accuracy_0_75).sum() / len(accuracy_0_75)\n",
    "\n",
    "# get recall\n",
    "recall_0_3 = np.array(accuracy_0_3).sum() / len(box_target)\n",
    "recall_0_5 = np.array(accuracy_0_5).sum() / len(box_target)\n",
    "recall_0_75 = np.array(accuracy_0_75).sum() / len(box_target)\n",
    "\n",
    "\n",
    "# mean iou on the train set\n",
    "print('mean iou on the train set:',mean_iou_m)\n",
    "\n",
    "# accuracy on the train set\n",
    "print('accuracy on the train set:', 'T=0.3',accuracy_0_3_m, 'T=0.5',accuracy_0_5_m, 'T=0.75',accuracy_0_75_m)\n",
    "\n",
    "# precision on the train set\n",
    "print('precision on the train set:', 'T=0.3',precision_0_3, 'T=0.5',precision_0_5, 'T=0.75',precision_0_75)\n",
    "\n",
    "# recall on the train set\n",
    "print('recall on the train set:', 'T=0.3',recall_0_3, 'T=0.5',recall_0_5, 'T=0.75',recall_0_75)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2573/2573 [00:00<00:00, 3149.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[275.,  26., 429., 152.],\n",
      "        [275.,  26., 429., 152.],\n",
      "        [308., 172., 499., 395.],\n",
      "        ...,\n",
      "        [238.,   0., 383., 258.],\n",
      "        [183.,  65., 430., 419.],\n",
      "        [183.,  65., 430., 419.]]) tensor([[285.0400,  23.2900, 424.7800, 146.4000],\n",
      "        [285.0400,  23.2900, 424.7800, 146.4000],\n",
      "        [183.4000,  68.3400, 310.2100, 167.1500],\n",
      "        ...,\n",
      "        [238.3800,   5.4700, 388.3100, 257.8700],\n",
      "        [177.8600,  67.1400, 430.8400, 419.5600],\n",
      "        [177.8600,  67.1400, 430.8400, 419.5600]])\n",
      "assert same dimensionality True\n",
      "torch.Size([4369, 4]) torch.Size([4369, 4])\n",
      "mean iou on the train set: 0.53202575\n",
      "accuracy on the train set: T=0.3 0.5781643396658275 T=0.5 0.5326161593041886 T=0.75 0.4998855573357748\n",
      "precision on the train set: T=0.3 0.5781643396658275 T=0.5 0.5326161593041886 T=0.75 0.4998855573357748\n",
      "recall on the train set: T=0.3 0.5781643396658275 T=0.5 0.5326161593041886 T=0.75 0.4998855573357748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "with open('./data/yolo_v8x/yolo_v8x_1_dictionary_full_val.p', 'rb') as f:\n",
    "    dictionary = pickle.load(f)\n",
    "\n",
    "\n",
    "def load_the_best_matching_box(dictionary):\n",
    "    box_target = []\n",
    "    box_pred = []\n",
    "    \n",
    "    # with open(file_name, 'rb') as f:\n",
    "    #     dictionary = pickle.load(f)\n",
    "        \n",
    "    for sample in tqdm(dictionary.keys()):\n",
    "        \n",
    "        try:\n",
    "            # get the sample\n",
    "            element = dictionary[sample]\n",
    "            \n",
    "            for sim, cap in zip(element['text_similarity'],element['caption']):\n",
    "                \n",
    "                # get the max similarity index\n",
    "                max_sim_index = torch.argmax(sim).numpy()\n",
    "                \n",
    "                # gete the  bbox_target\n",
    "                box_pred.append(element['df_boxes'].loc[max_sim_index][:4].values.astype('int'))\n",
    "                box_target.append(element['bbox_target'])\n",
    "        except:\n",
    "            KeyError: print('error in sample:', sample)\n",
    "            \n",
    "    box_pred = torch.stack([torch.Tensor(p) for p in box_pred])\n",
    "    box_target = torch.tensor(box_target)\n",
    "    \n",
    "    # convert the box_pred to x1, y1, x2, y2\n",
    "    box_target[:, 2] = box_target[:, 0] + box_target[:, 2]\n",
    "    box_target[:, 3] = box_target[:, 1] + box_target[:, 3]\n",
    "        \n",
    "    return box_pred, box_target\n",
    "\n",
    "\n",
    "\n",
    "box_pred, box_target = load_the_best_matching_box(dictionary)\n",
    "\n",
    "\n",
    "\n",
    "print(box_pred,box_target)\n",
    "\n",
    "\n",
    "print('assert same dimensionality',len(box_pred) == len(box_target))\n",
    "\n",
    "\n",
    "\n",
    "print(box_target.shape,  box_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "mean_iou = []\n",
    "accuracy_0_3 = []\n",
    "accuracy_0_5 = []\n",
    "accuracy_0_75 = []\n",
    "\n",
    "def iou(box1, box2):\n",
    "    # get the coordinates of bounding boxes\n",
    "    b1_x1, b1_y1, b1_x2, b1_y2 = box1\n",
    "    b2_x1, b2_y1, b2_x2, b2_y2 = box2\n",
    "    \n",
    "    # get the corrdinates of the intersection rectangle\n",
    "    inter_rect_x1 =  max(b1_x1, b2_x1)\n",
    "    inter_rect_y1 =  max(b1_y1, b2_y1)\n",
    "    inter_rect_x2 =  min(b1_x2, b2_x2)\n",
    "    inter_rect_y2 =  min(b1_y2, b2_y2)\n",
    "    \n",
    "    # Intersection area\n",
    "    inter_area = max(inter_rect_x2 - inter_rect_x1 + 1, 0) * max(inter_rect_y2 - inter_rect_y1 + 1, 0)\n",
    "    \n",
    "    # Union Area\n",
    "    b1_area = (b1_x2 - b1_x1 + 1)*(b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1)*(b2_y2 - b2_y1 + 1)\n",
    "    \n",
    "    iou = inter_area / (b1_area + b2_area - inter_area)\n",
    "    \n",
    "    return iou\n",
    "    \n",
    "for b_t, b_p in zip(box_target, box_pred):\n",
    "    \n",
    "    IoU = iou(b_t, b_p)\n",
    "\n",
    "    # get the iou\n",
    "    mean_iou.append(IoU)\n",
    "\n",
    "    # get the accuracy\n",
    "    if IoU > 0.3:\n",
    "        accuracy_0_3.append(1)\n",
    "    else:\n",
    "        accuracy_0_3.append(0)\n",
    "\n",
    "    if IoU > 0.5:\n",
    "        accuracy_0_5.append(1)\n",
    "    else:\n",
    "        accuracy_0_5.append(0)\n",
    "\n",
    "    if IoU > 0.75:\n",
    "        accuracy_0_75.append(1)\n",
    "    else:   \n",
    "        accuracy_0_75.append(0)\n",
    "\n",
    "# get the mean iou\n",
    "mean_iou_m = torch.stack(mean_iou).mean().numpy()\n",
    "\n",
    "\n",
    "# get the accuracy\n",
    "accuracy_0_3_m = np.array(accuracy_0_3).mean()\n",
    "accuracy_0_5_m = np.array(accuracy_0_5).mean()\n",
    "accuracy_0_75_m = np.array(accuracy_0_75).mean()\n",
    "\n",
    "# get precision\n",
    "precision_0_3 = np.array(accuracy_0_3).sum() / len(accuracy_0_3)\n",
    "precision_0_5 = np.array(accuracy_0_5).sum() / len(accuracy_0_5)\n",
    "precision_0_75 = np.array(accuracy_0_75).sum() / len(accuracy_0_75)\n",
    "\n",
    "# get recall\n",
    "recall_0_3 = np.array(accuracy_0_3).sum() / len(box_target)\n",
    "recall_0_5 = np.array(accuracy_0_5).sum() / len(box_target)\n",
    "recall_0_75 = np.array(accuracy_0_75).sum() / len(box_target)\n",
    "\n",
    "\n",
    "# mean iou on the train set\n",
    "print('mean iou on the train set:',mean_iou_m)\n",
    "\n",
    "# accuracy on the train set\n",
    "print('accuracy on the train set:', 'T=0.3',accuracy_0_3_m, 'T=0.5',accuracy_0_5_m, 'T=0.75',accuracy_0_75_m)\n",
    "\n",
    "# precision on the train set\n",
    "print('precision on the train set:', 'T=0.3',precision_0_3, 'T=0.5',precision_0_5, 'T=0.75',precision_0_75)\n",
    "\n",
    "# recall on the train set\n",
    "print('recall on the train set:', 'T=0.3',recall_0_3, 'T=0.5',recall_0_5, 'T=0.75',recall_0_75)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum number of boxes found:  48\n",
      "mean number of boxes found:  7.110292653792555\n",
      "std number of boxes found:  4.077023158130561\n",
      "count max number of boxes found:  0\n",
      "count of number of boxes found:\n",
      "[2, 55, 522, 757, 823, 708, 527, 350, 274, 190, 187, 152, 125, 72, 54, 49, 34, 34, 16, 17, 11, 16, 15, 8, 7, 4, 2, 1, 3, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "file_name = './data/yolo_v8x/yolo_v8x_1_dictionary_full_test.p'\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    dictionary = pickle.load(f)\n",
    "\n",
    "print('maximum number of boxes found: ',max([len(dictionary[sample]['image_emb']) for sample in dictionary.keys()]))\n",
    "print('mean number of boxes found: ',np.array([len(dictionary[sample]['image_emb']) for sample in dictionary.keys()]).mean())\n",
    "print('std number of boxes found: ',np.array([len(dictionary[sample]['image_emb']) for sample in dictionary.keys()]).std())\n",
    "print('count max number of boxes found: ',[len(dictionary[sample]['image_emb']) for sample in dictionary.keys()].count(32))\n",
    "print('count of number of boxes found:')\n",
    "print([[len(dictionary[sample]['image_emb']) for sample in dictionary.keys()].count(xx+1) for xx in range(32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum number of boxes found:  33\n",
      "mean number of boxes found:  7.382821609016712\n",
      "std number of boxes found:  4.111538592521283\n",
      "count max number of boxes found:  0\n",
      "count of number of boxes found:\n",
      "[0, 35, 227, 400, 409, 294, 262, 189, 153, 132, 102, 74, 67, 62, 43, 26, 15, 17, 22, 8, 12, 4, 6, 3, 0, 9, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "file_name = './data/yolo_v8x/yolo_v8x_1_dictionary_full_val.p'\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    dictionary = pickle.load(f)\n",
    "\n",
    "print('maximum number of boxes found: ',max([len(dictionary[sample]['image_emb']) for sample in dictionary.keys()]))\n",
    "print('mean number of boxes found: ',np.array([len(dictionary[sample]['image_emb']) for sample in dictionary.keys()]).mean())\n",
    "print('std number of boxes found: ',np.array([len(dictionary[sample]['image_emb']) for sample in dictionary.keys()]).std())\n",
    "print('count max number of boxes found: ',[len(dictionary[sample]['image_emb']) for sample in dictionary.keys()].count(32))\n",
    "print('count of number of boxes found:')\n",
    "print([[len(dictionary[sample]['image_emb']) for sample in dictionary.keys()].count(xx+1) for xx in range(32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum number of boxes found:  47\n",
      "mean number of boxes found:  7.235423672618766\n",
      "std number of boxes found:  4.153021557423283\n",
      "count max number of boxes found:  13\n",
      "count of number of boxes found:\n",
      "[18, 479, 4468, 5996, 6630, 5439, 4523, 3301, 2520, 2061, 1476, 1100, 856, 653, 635, 504, 348, 231, 234, 176, 114, 62, 73, 51, 65, 45, 32, 24, 19, 8, 16, 13]\n"
     ]
    }
   ],
   "source": [
    "file_name = './data/yolo_v8x/yolo_v8x_1_dictionary_full_train.p'\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    dictionary = pickle.load(f)\n",
    "\n",
    "print('maximum number of boxes found: ',max([len(dictionary[sample]['image_emb']) for sample in dictionary.keys()]))\n",
    "print('mean number of boxes found: ',np.array([len(dictionary[sample]['image_emb']) for sample in dictionary.keys()]).mean())\n",
    "print('std number of boxes found: ',np.array([len(dictionary[sample]['image_emb']) for sample in dictionary.keys()]).std())\n",
    "print('count max number of boxes found: ',[len(dictionary[sample]['image_emb']) for sample in dictionary.keys()].count(32))\n",
    "print('count of number of boxes found:')\n",
    "print([[len(dictionary[sample]['image_emb']) for sample in dictionary.keys()].count(xx+1) for xx in range(32)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3163cfb8aa3549ad3f5400bc3427ee7a4002d2a0d6d7ead52f641c6a7636395"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
