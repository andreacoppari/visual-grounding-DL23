{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rickbook/mambaforge/envs/pytorch2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(d_model, d_model//4)\n",
    "        # self.layer_norm1 = nn.LayerNorm(d_model//4)\n",
    "        self.linear2 = nn.Linear(d_model//4,  d_model//16)\n",
    "        # self.layer_norm2 = nn.LayerNorm(d_model//16)\n",
    "        self.linear3 = nn.Linear(d_model//16, d_model//32)\n",
    "        # self.layer_norm3 = nn.LayerNorm(d_model//32)\n",
    "        self.linear4 = nn.Linear(d_model//32, 4)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x = x.to(device)\n",
    "        # x = x.cuda()\n",
    "\n",
    "        # x = self.layer_norm1(self.dropout(self.linear1(x)))\n",
    "        # x = self.layer_norm2(self.dropout(self.linear2(x)))\n",
    "        # x = self.layer_norm3(self.dropout(self.linear3(x)))\n",
    "        # x = self.linear4(x)\n",
    "\n",
    "        x = self.dropout(self.activation(self.linear1(x)))\n",
    "        x = self.dropout(self.activation(self.linear2(x)))\n",
    "        x = self.dropout(self.activation(self.linear3(x)))\n",
    "        x = self.linear4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # embedding matching\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # feedforward\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        # activation\n",
    "        self.activation = nn.GELU()\n",
    "        \n",
    "    def forward(self, text_emb, box_emb):\n",
    "\n",
    "        # https://arxiv.org/pdf/2002.04745.pdf\n",
    "        # here we propose the original transformer encoder layer\n",
    "        # however, we designed the architecture in this way\n",
    "        # as the authors of the paper did to improve the convergence\n",
    "\n",
    "        # text_emb = text_emb.to(device)\n",
    "        # box_emb = box_emb.to(device)\n",
    "\n",
    "        # text_emb = text_emb.cuda()\n",
    "        # box_emb = box_emb.cuda()\n",
    "\n",
    "\n",
    "        # # Add & Norm\n",
    "        text_emb = text_emb + self.dropout1(text_emb)\n",
    "        text_emb = self.norm1(text_emb)\n",
    "\n",
    "        box_emb = box_emb + self.dropout1(box_emb)\n",
    "        box_emb = self.norm1(box_emb)\n",
    "\n",
    "        # print(text_emb.shape, box_emb.shape)\n",
    "\n",
    "        # embedding matching\n",
    "        x , _ = self.self_attn(box_emb, text_emb, text_emb)\n",
    "\n",
    "        # print(x.shape, box_emb.shape)\n",
    "        \n",
    "        # Add & Norm\n",
    "        x = box_emb + self.dropout2(x)\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        # feedforward\n",
    "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "\n",
    "        # x = box_emb + self.dropout2(x)\n",
    "        # x = self.norm2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # self.encoder_block = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "        # self.transformer_encoder = nn.TransformerEncoder(self.encoder_block, num_layers)\n",
    "\n",
    "        # self.transformer_encoder = [TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout).to(device).type(torch.float32) for _ in range(num_layers)]\n",
    "        self.transformer_encoder = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "\n",
    "\n",
    "    def forward(self, text_emb, box_emb):\n",
    "\n",
    "        # # matching between the text and the first box\n",
    "        # x0 = self.transformer_encoder(text_emb, box_emb[:,0,:].unsqueeze(1))\n",
    "        # # matching between the text and the second box\n",
    "        # x1 = self.transformer_encoder(text_emb, box_emb[:,1,:].unsqueeze(1))\n",
    "        \n",
    "        # # concatenate the two boxes\n",
    "        # # shape: (batch_size, 2, d_model)\n",
    "        # x = torch.cat([x0, x1], axis=1)\n",
    "\n",
    "\n",
    "        # text_emb = text_emb.to(device)\n",
    "        # box_emb = box_emb.to(device)\n",
    "\n",
    "        # text_emb = text_emb.cuda()\n",
    "        # box_emb = box_emb.cuda()\n",
    "        \n",
    "        x0 = text_emb\n",
    "        x1 = text_emb\n",
    "\n",
    "        # for layer in self.transformer_encoder:\n",
    "        #     # matching between the text and the first box\n",
    "        #     x0 = layer(x0, box_emb[:,0,:].unsqueeze(1))\n",
    "        #     # matching between the text and the second box\n",
    "        #     x1 = layer(x1, box_emb[:,1,:].unsqueeze(1))\n",
    "        \n",
    "        # matching between the text and the first box\n",
    "        x0 = self.transformer_encoder(x0, box_emb[:,0,:].unsqueeze(1))\n",
    "        \n",
    "        # matching between the text and the second box\n",
    "        x1 = self.transformer_encoder(x1, box_emb[:,1,:].unsqueeze(1))\n",
    "\n",
    "        # concatenate the two boxes\n",
    "        # shape: (batch_size, 2, d_model)\n",
    "        x = torch.cat([x0, x1], axis=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "class BoxRegressor(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.transformer_encoder = TransformerEncoder(d_model, nhead, num_layers, dim_feedforward, dropout)#.to(device).type(torch.float32)\n",
    "        # self.mlp_regressor = MLP(1034, dropout)#.to(device).type(torch.float32)\n",
    "        # self.mlp_regressor = MLP(10, dropout)#.to(device).type(torch.float32)\n",
    "\n",
    "        self.act = 1034\n",
    "        self.mlp_regressor = nn.Sequential(\n",
    "            nn.Linear(self.act, self.act//2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.act//2, self.act//4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.act//4, 4)\n",
    "        )\n",
    "        self.flatten = nn.Flatten(start_dim=1)#.to(device)\n",
    "\n",
    "\n",
    "    def forward(self, text_encoding, box_encoding, box_coords):\n",
    "\n",
    "        # text_encoding = text_encoding.to(device)\n",
    "        # box_encoding = box_encoding.to(device)\n",
    "        # box_coords = box_coords.to(device)\n",
    "\n",
    "        # text_encoding = text_encoding.cuda()\n",
    "        # box_encoding = box_encoding.cuda()\n",
    "        # box_coords = box_coords.cuda()\n",
    "\n",
    "        # compute the similarity matrix between the text and the boxes encoding\n",
    "        similarity_matrix = torch.bmm(text_encoding.permute(0, 2, 1), box_encoding)\n",
    "\n",
    "        # get the index of the top two boxes with the highest score\n",
    "        top2_indices = torch.topk(similarity_matrix, k=2, dim=-1).indices.squeeze(1)\n",
    "        top2 = torch.topk(similarity_matrix, k=2, dim=-1).indices.squeeze(1)\n",
    "\n",
    "\n",
    "        # permute the dimensions to get the top two boxes\n",
    "        box_encoding = box_encoding.permute(0, 2, 1)\n",
    "        # get the top two boxes\n",
    "        top2_boxes = box_encoding[torch.arange(box_encoding.shape[0]).unsqueeze(1), top2_indices]\n",
    "        # print(top2_boxes.shape)\n",
    "\n",
    "        # get the top two boxes coordinates\n",
    "        top2_boxes_coords = box_coords[torch.arange(box_encoding.shape[0]).unsqueeze(1), top2_indices]\n",
    "        # print(top2_boxes_coords.shape)\n",
    "\n",
    "        top2_boxes = top2_boxes.to(device)\n",
    "\n",
    "        # compute the matching between the text and the top two boxes\n",
    "        out_matching = self.transformer_encoder(text_encoding.permute(0, 2, 1), top2_boxes)\n",
    "\n",
    "        # concatenate the matching score with the top two boxes coordinates\n",
    "        matching_score = torch.cat([top2.unsqueeze(2), top2_boxes_coords, out_matching], axis=-1) # out_matching\n",
    "\n",
    "        # print(matching_score)\n",
    "        return self.mlp_regressor(self.flatten(matching_score))\n",
    "        # return self.flatten(matching_score)\n",
    "    \n",
    "\n",
    "\n",
    "# def SUM_MSE_loss(pred, target):\n",
    "#     return (pred - target).pow(2).sum(axis=-1).mean()\n",
    "\n",
    "from torch.nn import HuberLoss\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "# Pytorch Lightning\n",
    "#################################################################################\n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.box_regressor = BoxRegressor(d_model, nhead, num_layers, dim_feedforward, dropout)\n",
    "        self.loss = MSELoss()\n",
    "\n",
    "    def forward(self, text_encoding, box_encoding, box_coords):\n",
    "        return self.box_regressor(text_encoding, box_encoding, box_coords)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        text_encoding, box_encoding, box_coords, labels = batch\n",
    "\n",
    "        # text_encoding = text_encoding.to(device)\n",
    "        # box_encoding = box_encoding.to(device)\n",
    "        # box_coords = box_coords.to(device)\n",
    "        # labels = labels.to(device)\n",
    "\n",
    "        # text_encoding = text_encoding.cuda()\n",
    "        # box_encoding = box_encoding.cuda()\n",
    "        # box_coords = box_coords.cuda()\n",
    "        # labels = labels.cuda()\n",
    "\n",
    "        out = self(text_encoding, box_encoding, box_coords)\n",
    "\n",
    "        labels = labels.squeeze(1)\n",
    "        # loss = F.mse_loss(1/(out+1), 1/(labels+1))\n",
    "        loss = self.loss(out, labels)\n",
    "        # loss = SUM_MSE_loss(out, labels)\n",
    "\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('train_loss', loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        text_encoding, box_encoding, box_coords, labels = batch\n",
    "\n",
    "        # text_encoding = text_encoding.to(device)\n",
    "        # box_encoding = box_encoding.to(device)\n",
    "        # box_coords = box_coords.to(device)\n",
    "        # labels = labels.to(device)\n",
    "\n",
    "        # text_encoding = text_encoding.cuda()\n",
    "        # box_encoding = box_encoding.cuda()\n",
    "        # box_coords = box_coords.cuda()\n",
    "        # labels = labels.cuda()\n",
    "\n",
    "        out = self(text_encoding, box_encoding, box_coords)\n",
    "\n",
    "        labels = labels.squeeze(1)\n",
    "\n",
    "        # loss = F.mse_loss(1/(out+1), 1/(labels+1))\n",
    "        loss = self.loss(out, labels)/labels.shape[0]\n",
    "        # loss = SUM_MSE_loss(out, labels)\n",
    "\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=5e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "# Pytorch\n",
    "#################################################################################\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self, d_model, nhead, num_layers, dim_feedforward, dropout=0.1):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.box_regressor = BoxRegressor(d_model, nhead, num_layers, dim_feedforward, dropout)\n",
    "\n",
    "#     def forward(self, text_encoding, box_encoding, box_coords):\n",
    "#         return self.box_regressor(text_encoding, box_encoding, box_coords)\n",
    "\n",
    "\n",
    "# def training(model, train_loader, val_loader, optimizer, criterion = MSELoss(), device = 'cuda', epochs = 10):\n",
    "\n",
    "#     sample = 0.0\n",
    "#     cum_loss = 0.0\n",
    "\n",
    "#     for e in range(epochs):\n",
    "\n",
    "#         model.train()\n",
    "        \n",
    "#         for batch_idx, (text_encoding, box_encoding, box_coords, labels) in enumerate(train_loader):\n",
    "\n",
    "#             text_encoding = text_encoding.cuda()\n",
    "#             box_encoding = box_encoding.cuda()\n",
    "#             box_coords = box_coords.cuda()\n",
    "\n",
    "#             labels = labels.cuda()\n",
    "\n",
    "#             output = model(text_encoding, box_encoding, box_coords)\n",
    "\n",
    "#             # output = output.squeeze(1)\n",
    "#             labels = labels.squeeze(1)\n",
    "\n",
    "#             # print(output - labels)\n",
    "#             # print(output)\n",
    "#             # print(output.shape, labels.shape)\n",
    "\n",
    "#             loss = criterion(output, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             sample += len(text_encoding)\n",
    "#             cum_loss += loss.item()\n",
    "\n",
    "#         test_fn(model, val_loader, MSELoss(), device)\n",
    "\n",
    "#         print(f'Train Epoch: {e} Loss: {cum_loss/sample}')    \n",
    "\n",
    "\n",
    "# def test_fn(model, test_loader, criterion = MSELoss(), device = 'cuda'):\n",
    "\n",
    "#     sample = 0.0\n",
    "#     cum_loss = 0.0\n",
    "\n",
    "#     model.eval()\n",
    "\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (text_encoding, box_encoding, box_coords, labels) in enumerate(test_loader):\n",
    "\n",
    "#             text_encoding = text_encoding.cuda()\n",
    "#             box_encoding = box_encoding.cuda()\n",
    "#             box_coords = box_coords.cuda()\n",
    "\n",
    "#             labels = labels.cuda()\n",
    "\n",
    "#             output = model(text_encoding, box_encoding, box_coords)\n",
    "\n",
    "#             # output = output.squeeze(1)\n",
    "#             labels = labels.squeeze(1)\n",
    "\n",
    "#             loss = criterion(output, labels)\n",
    "\n",
    "#             # print(loss)\n",
    "            \n",
    "#             sample += len(text_encoding)\n",
    "#             cum_loss += loss.item()\n",
    "\n",
    "#         print(f'Test Loss: {cum_loss/sample}')      \n",
    "\n",
    "# # init model\n",
    "# model = Net(512, 1, 1, 10, 0.1).cuda()\n",
    "\n",
    "# print(model)\n",
    "# print('number of parameter: ',sum(p.numel() for p in model.parameters() if p.requires_grad)/1000000.0, 'M')\n",
    "\n",
    "\n",
    "# # del dataset_test, dataset_train, dataset_val\n",
    "\n",
    "# batch_size = 256\n",
    "\n",
    "# dataset_test = TensorDataset(text_encoding_test.type(torch.float32), box_encoding_test.type(torch.float32), box_coords_test.type(torch.float32), target_boxes_test.type(torch.float32))\n",
    "# dataset_val = TensorDataset(text_encoding_val.type(torch.float32), box_encoding_val.type(torch.float32), box_coords_val.type(torch.float32), target_boxes_val.type(torch.float32))\n",
    "# # dataset_test = TensorDataset(text_encoding_test, box_encoding_test, box_coords_test, target_boxes_test)\n",
    "# # dataset_val = TensorDataset(text_encoding_val, box_encoding_val, box_coords_val, target_boxes_val)\n",
    "# # dataset_train = TensorDataset(text_encoding_train, box_encoding_train, box_coords_train, target_boxes_train)\n",
    "\n",
    "\n",
    "# test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# training(model, test_loader, val_loader, torch.optim.AdamW(model.parameters(), lr=5e-4), MSELoss(), device, 50)\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "# Simple random data\n",
    "#################################################################################\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(device)\n",
    "\n",
    "# text_encoding = torch.randn(10000, 512, 1).to(device)\n",
    "# box_encoding = torch.randn(10000, 512, 10).to(device)\n",
    "# box_coords = torch.randn(10000, 10, 4).to(device)\n",
    "# target_boxes = torch.randn(10000, 1, 4).to(device)\n",
    "\n",
    "\n",
    "# # get dataset\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# batch_size = 256\n",
    "\n",
    "# dataset = TensorDataset(text_encoding, box_encoding, box_coords, target_boxes)\n",
    "# train_loader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "\n",
    "# # init model\n",
    "# model = Net(512, 8, 2, 2048, 0.1).cuda()\n",
    "\n",
    "# print(model)\n",
    "# print('number of parameter: ',sum(p.numel() for p in model.parameters() if p.requires_grad)/1000000.0, 'M')\n",
    "\n",
    "# # most basic trainer, uses good defaults\n",
    "# trainer = pl.Trainer(accelerator='auto', max_epochs=10)\n",
    "\n",
    "# # train the model\n",
    "# trainer.fit(model, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "import pickle\n",
    "\n",
    "# # load test dataset\n",
    "# file_name = './data/yolo_v8x/yolo_v8x_1_dictionary_full_test.p'\n",
    "# with open(file_name, 'rb') as f:\n",
    "#     data_test = pickle.load(f)\n",
    "\n",
    "# load val dataset\n",
    "file_name = './data/yolo_v8x/yolo_v8x_1_dictionary_full_val.p'\n",
    "with open(file_name, 'rb') as f:\n",
    "    data_val = pickle.load(f)\n",
    "\n",
    "# load train dataset\n",
    "file_name = './data/yolo_v8x/yolo_v8x_1_dictionary_full_train.p'\n",
    "with open(file_name, 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# text_encoding = torch.randn(10000, 512, 1).to(device)\n",
    "# box_encoding = torch.randn(10000, 512, 10).to(device)\n",
    "# box_coords = torch.randn(10000, 10, 4).to(device)\n",
    "# target_boxes = torch.randn(10000, 1, 4).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2573/2573 [00:05<00:00, 445.01it/s]\n",
      "100%|██████████| 42226/42226 [01:20<00:00, 525.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_data(full_data):\n",
    "\n",
    "    text_encoding, box_encoding, box_coords, target_boxes = [], [], [], []\n",
    "\n",
    "    for idx in tqdm(list(full_data)):\n",
    "        # for _ in range(data['image_emb'].shape[0]):\n",
    "        for idx_text in range(full_data[idx]['text_emb'].shape[0]):\n",
    "            \n",
    "            # number of available crops\n",
    "            number_of_crop = min(full_data[idx]['image_emb'].shape[0], len(full_data[idx]['df_boxes']))\n",
    "\n",
    "            if number_of_crop == 0:\n",
    "                break\n",
    "\n",
    "            # shape: (number of samples, 512, 1)\n",
    "            text_encoding.append(full_data[idx]['text_emb'][idx_text].unsqueeze(1))\n",
    "\n",
    "            number_of_crop = min(full_data[idx]['image_emb'].shape[0], len(full_data[idx]['df_boxes']))\n",
    "\n",
    "            # shape: (number of samples, 512, number of crop embeddings)\n",
    "            box_encoding.append(full_data[idx]['image_emb'][:number_of_crop,:].permute(1, 0))\n",
    "\n",
    "            # shape: (number of samples, number of boxes, 4)\n",
    "            box_coords.append(torch.stack([torch.tensor(full_data[idx]['df_boxes'].iloc[i][:4]).type(torch.float16) \n",
    "                                                    for i in range(number_of_crop)]))\n",
    "            \n",
    "            # shape: (number of samples, 1, 4)\n",
    "            target_boxes.append(torch.tensor(full_data[idx]['bbox_target']).type(torch.float16).unsqueeze(0))\n",
    "\n",
    "    return torch.stack(text_encoding), torch.stack([torch.nn.functional.pad(b.permute(1, 0), (0, 0, 0, 48 - b.shape[1])).permute(1, 0) for b in box_encoding]), torch.stack([torch.nn.functional.pad(b, (0, 0, 0, 48 - b.shape[0])) for b in box_coords]), torch.stack(target_boxes)\n",
    "\n",
    "\n",
    "\n",
    "# text_encoding_test, box_encoding_test, box_coords_test, target_boxes_test = get_data(data_test)\n",
    "text_encoding_val, box_encoding_val, box_coords_val, target_boxes_val = get_data(data_val)\n",
    "text_encoding_train, box_encoding_train, box_coords_train, target_boxes_train = get_data(data_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_norm_rescale(box_target):\n",
    "    \"\"\" Rescale the box_target \n",
    "    Args:\n",
    "        box_target: (number of samples, 1, 4)\n",
    "\n",
    "    Returns:\n",
    "        box_target: (number of samples, 1, 4)\n",
    "\n",
    "    \"\"\"\n",
    "    # convert the box_pred to x1, y1, x2, y2\n",
    "    box_target[:, 0, 2] = box_target[:, 0, 0] + box_target[:, 0, 2]\n",
    "    box_target[:, 0, 3] = box_target[:, 0, 1] + box_target[:, 0, 3]\n",
    "\n",
    "    return box_target\n",
    "\n",
    "# box rescaling\n",
    "# target_boxes_test = box_norm_rescale(target_boxes_test)\n",
    "target_boxes_val = box_norm_rescale(target_boxes_val)\n",
    "target_boxes_train = box_norm_rescale(target_boxes_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (box_regressor): BoxRegressor(\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (transformer_encoder): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=32, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=32, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (activation): GELU(approximate='none')\n",
      "      )\n",
      "    )\n",
      "    (mlp_regressor): Sequential(\n",
      "      (0): Linear(in_features=1034, out_features=517, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=517, out_features=258, bias=True)\n",
      "      (4): GELU(approximate='none')\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=258, out_features=4, bias=True)\n",
      "    )\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (loss): MSELoss()\n",
      ")\n",
      "number of parameter:  1.755759 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type         | Params\n",
      "-----------------------------------------------\n",
      "0 | box_regressor | BoxRegressor | 1.8 M \n",
      "1 | loss          | MSELoss      | 0     \n",
      "-----------------------------------------------\n",
      "1.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 M     Total params\n",
      "7.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rickbook/mambaforge/envs/pytorch2/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:478: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/rickbook/mambaforge/envs/pytorch2/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rickbook/mambaforge/envs/pytorch2/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 158/158 [00:06<00:00, 23.62it/s, v_num=57]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 22.791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 158/158 [00:05<00:00, 28.66it/s, v_num=57]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 1.132 >= min_delta = 0.0. New best score: 21.658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 158/158 [00:24<00:00,  6.36it/s, v_num=57]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.240 >= min_delta = 0.0. New best score: 21.418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 158/158 [00:05<00:00, 29.64it/s, v_num=57]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.071 >= min_delta = 0.0. New best score: 21.347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 158/158 [00:05<00:00, 28.86it/s, v_num=57]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.031 >= min_delta = 0.0. New best score: 21.316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 158/158 [00:05<00:00, 28.99it/s, v_num=57]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 4 records. Best score: 21.316. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 158/158 [00:05<00:00, 28.81it/s, v_num=57]\n"
     ]
    }
   ],
   "source": [
    "# dataloaders\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "# dataset_test = TensorDataset(text_encoding_test, box_encoding_test, box_coords_test, target_boxes_test)\n",
    "# dataset_val = TensorDataset(text_encoding_val, box_encoding_val, box_coords_val, target_boxes_val)\n",
    "# dataset_train = TensorDataset(text_encoding_train, box_encoding_train, box_coords_train, target_boxes_train)\n",
    "\n",
    "dataset_val = TensorDataset(text_encoding_val.type(torch.float32), box_encoding_val.type(torch.float32), box_coords_val.type(torch.float32), target_boxes_val[:20000].type(torch.float32))\n",
    "dataset_train = TensorDataset(text_encoding_train.type(torch.float32), box_encoding_train.type(torch.float32), box_coords_train.type(torch.float32), target_boxes_train.type(torch.float32))\n",
    "\n",
    "# test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# init model\n",
    "model = Net(512, 2, 1, 32, 0.1).cuda()\n",
    "\n",
    "print(model)\n",
    "print('number of parameter: ',sum(p.numel() for p in model.parameters() if p.requires_grad)/1000000.0, 'M')\n",
    "\n",
    "# most basic trainer, uses good defaults\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=4, verbose=True, mode=\"min\")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(accelerator='auto', max_epochs=30, callbacks=[early_stop_callback])\n",
    "\n",
    "# train the model\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# test the model\n",
    "# trainer.test(test_dataloaders=test_loader)\n",
    "\n",
    "# max([b.shape[0] for b in box_coords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 1 6.852848301124163 4.310411508820321\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(max([b.shape[0] for b in box_coords]), min([b.shape[0] for b in box_coords]), np.array([b.shape[0] for b in box_coords]).mean(), np.array([b.shape[0] for b in box_coords]).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_encoding = torch.randn(10000, 512, 1).to(device)\n",
    "# box_encoding = torch.randn(10000, 512, 10).to(device)\n",
    "# box_coords = torch.randn(10000, 10, 4).to(device)\n",
    "# target_boxes = torch.randn(10000, 1, 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(d_model, d_model//4)\n",
    "        # self.layer_norm1 = nn.LayerNorm(d_model//4)\n",
    "        self.linear2 = nn.Linear(d_model//4,  d_model//16)\n",
    "        # self.layer_norm2 = nn.LayerNorm(d_model//16)\n",
    "        self.linear3 = nn.Linear(d_model//16, d_model//32)\n",
    "        # self.layer_norm3 = nn.LayerNorm(d_model//32)\n",
    "        self.linear4 = nn.Linear(d_model//32, 4)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x = x.to(device)\n",
    "        # x = x.cuda()\n",
    "\n",
    "        # x = self.layer_norm1(self.dropout(self.linear1(x)))\n",
    "        # x = self.layer_norm2(self.dropout(self.linear2(x)))\n",
    "        # x = self.layer_norm3(self.dropout(self.linear3(x)))\n",
    "        # x = self.linear4(x)\n",
    "\n",
    "        x = self.dropout(self.activation(self.linear1(x)))\n",
    "        x = self.dropout(self.activation(self.linear2(x)))\n",
    "        x = self.dropout(self.activation(self.linear3(x)))\n",
    "        x = self.linear4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # embedding matching\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # feedforward\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        # activation\n",
    "        self.activation = nn.GELU()\n",
    "        \n",
    "    def forward(self, text_emb, box_emb):\n",
    "\n",
    "        # https://arxiv.org/pdf/2002.04745.pdf\n",
    "        # here we propose the original transformer encoder layer\n",
    "        # however, we designed the architecture in this way\n",
    "        # as the authors of the paper did to improve the convergence\n",
    "\n",
    "        # text_emb = text_emb.to(device)\n",
    "        # box_emb = box_emb.to(device)\n",
    "\n",
    "        # text_emb = text_emb.cuda()\n",
    "        # box_emb = box_emb.cuda()\n",
    "\n",
    "\n",
    "        # Add & Norm\n",
    "        text_emb = text_emb + self.dropout1(text_emb)\n",
    "        text_emb = self.norm1(text_emb)\n",
    "\n",
    "        box_emb = box_emb + self.dropout1(box_emb)\n",
    "        box_emb = self.norm1(box_emb)\n",
    "\n",
    "        # print(text_emb.shape, box_emb.shape)\n",
    "\n",
    "        # embedding matching\n",
    "        x , _ = self.self_attn(box_emb, text_emb, text_emb)\n",
    "\n",
    "        # print(x.shape, box_emb.shape)\n",
    "        \n",
    "        # Add & Norm\n",
    "        x = box_emb + self.dropout2(x)\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        # feedforward\n",
    "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "\n",
    "        # x = box_emb + self.dropout2(x)\n",
    "        # x = self.norm2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # self.encoder_block = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "        # self.transformer_encoder = nn.TransformerEncoder(self.encoder_block, num_layers)\n",
    "\n",
    "        # self.transformer_encoder = [TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout).to(device).type(torch.float32) for _ in range(num_layers)]\n",
    "        self.transformer_encoder = TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
    "\n",
    "\n",
    "    def forward(self, text_emb, box_emb):\n",
    "\n",
    "        # # matching between the text and the first box\n",
    "        # x0 = self.transformer_encoder(text_emb, box_emb[:,0,:].unsqueeze(1))\n",
    "        # # matching between the text and the second box\n",
    "        # x1 = self.transformer_encoder(text_emb, box_emb[:,1,:].unsqueeze(1))\n",
    "        \n",
    "        # # concatenate the two boxes\n",
    "        # # shape: (batch_size, 2, d_model)\n",
    "        # x = torch.cat([x0, x1], axis=1)\n",
    "\n",
    "\n",
    "        # text_emb = text_emb.to(device)\n",
    "        # box_emb = box_emb.to(device)\n",
    "\n",
    "        # text_emb = text_emb.cuda()\n",
    "        # box_emb = box_emb.cuda()\n",
    "        \n",
    "        x0 = text_emb\n",
    "        x1 = text_emb\n",
    "\n",
    "        # for layer in self.transformer_encoder:\n",
    "        #     # matching between the text and the first box\n",
    "        #     x0 = layer(x0, box_emb[:,0,:].unsqueeze(1))\n",
    "        #     # matching between the text and the second box\n",
    "        #     x1 = layer(x1, box_emb[:,1,:].unsqueeze(1))\n",
    "        \n",
    "        # matching between the text and the first box\n",
    "        x0 = self.transformer_encoder(x0, box_emb[:,0,:].unsqueeze(1))\n",
    "        \n",
    "        # matching between the text and the second box\n",
    "        x1 = self.transformer_encoder(x1, box_emb[:,1,:].unsqueeze(1))\n",
    "\n",
    "        # concatenate the two boxes\n",
    "        # shape: (batch_size, 2, d_model)\n",
    "        x = torch.cat([x0, x1], axis=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "class BoxRegressor(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # self.transformer_encoder = TransformerEncoder(d_model, nhead, num_layers, dim_feedforward, dropout)#.to(device).type(torch.float32)\n",
    "        # self.mlp_regressor = MLP(1034, dropout)#.to(device).type(torch.float32)\n",
    "        # self.mlp_regressor = MLP(10, dropout)#.to(device).type(torch.float32)\n",
    "\n",
    "        self.act = 10\n",
    "        self.mlp_regressor = nn.Sequential(\n",
    "            nn.Linear(self.act, self.act//2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.act//2, self.act//4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.act//4, 4)\n",
    "        )\n",
    "        self.flatten = nn.Flatten(start_dim=1)#.to(device)\n",
    "\n",
    "\n",
    "    def forward(self, text_encoding, box_encoding, box_coords):\n",
    "\n",
    "        # text_encoding = text_encoding.to(device)\n",
    "        # box_encoding = box_encoding.to(device)\n",
    "        # box_coords = box_coords.to(device)\n",
    "\n",
    "        # text_encoding = text_encoding.cuda()\n",
    "        # box_encoding = box_encoding.cuda()\n",
    "        # box_coords = box_coords.cuda()\n",
    "\n",
    "        # compute the similarity matrix between the text and the boxes encoding\n",
    "        similarity_matrix = torch.bmm(text_encoding.permute(0, 2, 1), box_encoding)\n",
    "\n",
    "        # get the index of the top two boxes with the highest score\n",
    "        top2_indices = torch.topk(similarity_matrix, k=2, dim=-1).indices.squeeze(1)\n",
    "        top2 = torch.topk(similarity_matrix, k=2, dim=-1).indices.squeeze(1)\n",
    "\n",
    "\n",
    "        # permute the dimensions to get the top two boxes\n",
    "        box_encoding = box_encoding.permute(0, 2, 1)\n",
    "        # get the top two boxes\n",
    "        top2_boxes = box_encoding[torch.arange(box_encoding.shape[0]).unsqueeze(1), top2_indices]\n",
    "        # print(top2_boxes.shape)\n",
    "\n",
    "        # get the top two boxes coordinates\n",
    "        top2_boxes_coords = box_coords[torch.arange(box_encoding.shape[0]).unsqueeze(1), top2_indices]\n",
    "        # print(top2_boxes_coords.shape)\n",
    "\n",
    "        top2_boxes = top2_boxes.to(device)\n",
    "\n",
    "        # compute the matching between the text and the top two boxes\n",
    "        # out_matching = self.transformer_encoder(text_encoding.permute(0, 2, 1), top2_boxes)\n",
    "\n",
    "        # concatenate the matching score with the top two boxes coordinates\n",
    "        matching_score = torch.cat([top2.unsqueeze(2), top2_boxes_coords], axis=-1) # out_matching\n",
    "\n",
    "        # print(matching_score)\n",
    "        return self.mlp_regressor(self.flatten(matching_score))\n",
    "        # return self.flatten(matching_score)\n",
    "    \n",
    "\n",
    "\n",
    "# def SUM_MSE_loss(pred, target):\n",
    "#     return (pred - target).pow(2).sum(axis=-1).mean()\n",
    "\n",
    "from torch.nn import HuberLoss\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "# Pytorch Lightning\n",
    "#################################################################################\n",
    "\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.box_regressor = BoxRegressor(d_model, nhead, num_layers, dim_feedforward, dropout)\n",
    "        self.loss = MSELoss()\n",
    "\n",
    "    def forward(self, text_encoding, box_encoding, box_coords):\n",
    "        return self.box_regressor(text_encoding, box_encoding, box_coords)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        text_encoding, box_encoding, box_coords, labels = batch\n",
    "\n",
    "        # text_encoding = text_encoding.to(device)\n",
    "        # box_encoding = box_encoding.to(device)\n",
    "        # box_coords = box_coords.to(device)\n",
    "        # labels = labels.to(device)\n",
    "\n",
    "        # text_encoding = text_encoding.cuda()\n",
    "        # box_encoding = box_encoding.cuda()\n",
    "        # box_coords = box_coords.cuda()\n",
    "        # labels = labels.cuda()\n",
    "\n",
    "        out = self(text_encoding, box_encoding, box_coords)\n",
    "\n",
    "        labels = labels.squeeze(1)\n",
    "        # loss = F.mse_loss(1/(out+1), 1/(labels+1))\n",
    "        loss = self.loss(out, labels)\n",
    "        # loss = SUM_MSE_loss(out, labels)\n",
    "\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('train_loss', loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        text_encoding, box_encoding, box_coords, labels = batch\n",
    "\n",
    "        # text_encoding = text_encoding.to(device)\n",
    "        # box_encoding = box_encoding.to(device)\n",
    "        # box_coords = box_coords.to(device)\n",
    "        # labels = labels.to(device)\n",
    "\n",
    "        # text_encoding = text_encoding.cuda()\n",
    "        # box_encoding = box_encoding.cuda()\n",
    "        # box_coords = box_coords.cuda()\n",
    "        # labels = labels.cuda()\n",
    "\n",
    "        out = self(text_encoding, box_encoding, box_coords)\n",
    "\n",
    "        labels = labels.squeeze(1)\n",
    "\n",
    "        # loss = F.mse_loss(1/(out+1), 1/(labels+1))\n",
    "        loss = self.loss(out, labels)/labels.shape[0]\n",
    "        # loss = SUM_MSE_loss(out, labels)\n",
    "\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=5e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (box_regressor): BoxRegressor(\n",
      "    (mlp_regressor): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=5, out_features=2, bias=True)\n",
      "      (4): GELU(approximate='none')\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=2, out_features=4, bias=True)\n",
      "    )\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (loss): MSELoss()\n",
      ")\n",
      "number of parameter:  7.9e-05 M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type         | Params\n",
      "-----------------------------------------------\n",
      "0 | box_regressor | BoxRegressor | 79    \n",
      "1 | loss          | MSELoss      | 0     \n",
      "-----------------------------------------------\n",
      "79        Trainable params\n",
      "0         Non-trainable params\n",
      "79        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rickbook/mambaforge/envs/pytorch2/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:478: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/rickbook/mambaforge/envs/pytorch2/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rickbook/mambaforge/envs/pytorch2/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 158/158 [00:05<00:00, 26.64it/s, v_num=56]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 178.728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 158/158 [00:24<00:00,  6.39it/s, v_num=56]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 65.368 >= min_delta = 0.0. New best score: 113.361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 158/158 [00:04<00:00, 34.54it/s, v_num=56]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 4.737 >= min_delta = 0.0. New best score: 108.624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 158/158 [00:04<00:00, 34.85it/s, v_num=56]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 3.629 >= min_delta = 0.0. New best score: 104.995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 158/158 [00:04<00:00, 32.49it/s, v_num=56]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.486 >= min_delta = 0.0. New best score: 104.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 158/158 [00:04<00:00, 34.12it/s, v_num=56]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.159 >= min_delta = 0.0. New best score: 104.349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 158/158 [00:04<00:00, 36.01it/s, v_num=56]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.136 >= min_delta = 0.0. New best score: 104.214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:04<00:00, 37.95it/s, v_num=56]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 104.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 158/158 [00:05<00:00, 28.03it/s, v_num=56]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.173 >= min_delta = 0.0. New best score: 104.032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 158/158 [00:04<00:00, 34.55it/s, v_num=56]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.085 >= min_delta = 0.0. New best score: 103.947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 158/158 [00:04<00:00, 35.58it/s, v_num=56]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 4 records. Best score: 103.947. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 158/158 [00:04<00:00, 35.53it/s, v_num=56]\n"
     ]
    }
   ],
   "source": [
    "# dataloaders\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "# dataset_test = TensorDataset(text_encoding_test, box_encoding_test, box_coords_test, target_boxes_test)\n",
    "# dataset_val = TensorDataset(text_encoding_val, box_encoding_val, box_coords_val, target_boxes_val)\n",
    "# dataset_train = TensorDataset(text_encoding_train, box_encoding_train, box_coords_train, target_boxes_train)\n",
    "\n",
    "dataset_val = TensorDataset(text_encoding_val.type(torch.float32), box_encoding_val.type(torch.float32), box_coords_val.type(torch.float32), target_boxes_val[:20000].type(torch.float32))\n",
    "dataset_train = TensorDataset(text_encoding_train.type(torch.float32), box_encoding_train.type(torch.float32), box_coords_train.type(torch.float32), target_boxes_train.type(torch.float32))\n",
    "\n",
    "# test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# init model\n",
    "model = Net(512, 2, 1, 32, 0.1).cuda()\n",
    "\n",
    "print(model)\n",
    "print('number of parameter: ',sum(p.numel() for p in model.parameters() if p.requires_grad)/1000000.0, 'M')\n",
    "\n",
    "# most basic trainer, uses good defaults\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=4, verbose=True, mode=\"min\")\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(accelerator='auto', max_epochs=30, callbacks=[early_stop_callback])\n",
    "\n",
    "# train the model\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# test the model\n",
    "# trainer.test(test_dataloaders=test_loader)\n",
    "\n",
    "# max([b.shape[0] for b in box_coords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8b82f6eb412fe2a6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8b82f6eb412fe2a6\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3163cfb8aa3549ad3f5400bc3427ee7a4002d2a0d6d7ead52f641c6a7636395"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
