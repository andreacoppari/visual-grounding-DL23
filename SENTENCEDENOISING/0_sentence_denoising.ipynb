{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "input_sentence = \"They were there to enjoy us and they were there to pray for us.\"\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained('eugenesiow/bart-paraphrase')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "tokenizer = BartTokenizer.from_pretrained('eugenesiow/bart-paraphrase')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardotedoldi/mambaforge/envs/ml/lib/python3.10/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  4.072089195251465\n",
      "['A purple elephant is flying in the sky, surrounded by pink clouds.', 'The Eiffel tower is tall in the middle of a dense forest.', 'A group of penguins is sunbathing on a sandy beach.', 'A rainbow-colored dinosaur is chasing a school bus on a city street.', 'A mermaid is swimming in a fish tank filled with colorful tropical fish.', 'A spaceship has landed on a snowy mountaintop, next to a cozy cabin.', 'A giant cupcake is floating in the ocean, attracting seagulls.', 'A giraffe is riding a bicycle in a crowded amusement park.', 'A waterfall flows through a desert landscape with cacti and sand dunes.']\n"
     ]
    }
   ],
   "source": [
    "input_sentence = [\n",
    "    \"A purple elephant is flying in the sky, surrounded by pink clouds.\",\n",
    "    \"The Eiffel Tower is standing tall in the middle of a dense forest.\",\n",
    "    \"A group of penguins is sunbathing on a sandy beach.\",\n",
    "    \"A rainbow-colored dinosaur is chasing a school bus on a city street.\",\n",
    "    \"A mermaid is swimming in a fish tank filled with colorful tropical fish.\",\n",
    "    \"A spaceship is landing on a snowy mountaintop, next to a cozy cabin.\",\n",
    "    \"A giant cupcake is floating in the ocean, attracting seagulls.\",\n",
    "    \"A giraffe is riding a bicycle in a crowded amusement park.\",\n",
    "    \"A waterfall is flowing through a desert landscape with cacti and sand dunes.\"\n",
    "]\n",
    "\n",
    "batch = tokenizer(input_sentence, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "translated = model.generate(**batch)\n",
    "generated_sentences = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time taken in seconds: \", end - start)\n",
    "\n",
    "print(generated_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3163cfb8aa3549ad3f5400bc3427ee7a4002d2a0d6d7ead52f641c6a7636395"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
